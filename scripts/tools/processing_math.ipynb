{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustrefs/users/shibo.hao/miniforge3/envs/Reasoning360/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 1791700/1791700 [00:19<00:00, 89867.85 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# load data from https://huggingface.co/datasets/BytedTsinghua-SIA/DAPO-Math-17k\n",
    "\n",
    "import datasets\n",
    "dataset = datasets.load_dataset(\"BytedTsinghua-SIA/DAPO-Math-17k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 1791700\n",
      "Deduplicated dataset size: 17917\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset)\n",
    "# Deduplicate based on the index in extra_info\n",
    "df['index'] = df['extra_info'].apply(lambda x: x['index'])\n",
    "df_deduped = df.drop_duplicates(subset=['index'])\n",
    "\n",
    "# Convert back to HuggingFace dataset\n",
    "deduped_dataset = datasets.Dataset.from_pandas(df_deduped)\n",
    "\n",
    "print(f\"Original dataset size: {len(dataset)}\")\n",
    "print(f\"Deduplicated dataset size: {len(deduped_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 17917/17917 [00:00<00:00, 546620.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# save the deduplicated dataset\n",
    "deduped_dataset.save_to_disk(\"deduplicated_dapo_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3150576/2521534035.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_deduped['original_question'] = df_deduped['prompt'].apply(\n",
      "/tmp/ipykernel_3150576/2521534035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_deduped['prompt'] = df_deduped['original_question'].apply(\n"
     ]
    }
   ],
   "source": [
    "# add a new column \"original_question\"\n",
    "df_deduped['original_question'] = df_deduped['prompt'].apply(\n",
    "    lambda x: x[0]['content'].split('Answer is the answer to the problem.\\n\\n')[1].split('\\n\\nRemember to put your answer on its own line after')[0].strip()\n",
    ")\n",
    "\n",
    "df_deduped['prompt'] = df_deduped['original_question'].apply(\n",
    "    lambda x: [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": x + \" Please output the final answer within \\\\boxed{}.\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_dataset = datasets.Dataset.from_pandas(df_deduped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 17917/17917 [00:00<00:00, 268451.88 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 18/18 [00:00<00:00, 200.14ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/SDSB/deduplicated_dapo_dataset/commit/bc74ffe1a450053df18db8656add2dbba0a9f90f', commit_message='Upload dataset', commit_description='', oid='bc74ffe1a450053df18db8656add2dbba0a9f90f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/SDSB/deduplicated_dapo_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='SDSB/deduplicated_dapo_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deduped_dataset = datasets.Dataset.from_pandas(df_deduped)\n",
    "deduped_dataset.save_to_disk(\"deduplicated_dapo_dataset\")\n",
    "# upload to my huggingface account\n",
    "deduped_dataset.push_to_hub(\"SDSB/deduplicated_dapo_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_source': 'train-math-numinamath1.5_olympiads', 'prompt': [{'content': '33. How many six-digit numbers are there in which all digits are odd?', 'role': 'user'}], 'ability': 'math', 'reward_model': {'ground_truth': '[\"15625\"]', 'style': 'rule'}, 'extra_info': {'index': 7, 'model_difficulty': {'DeepSeek-R1-Distill-Qwen-1.5B': 2, 'DeepSeek-R1-Distill-Qwen-32B': 2, 'DeepSeek-R1-Distill-Qwen-7B': 1}}}\n"
     ]
    }
   ],
   "source": [
    "# load Skywork/Skywork-OR1-RL-Data\n",
    "\n",
    "dataset = datasets.load_dataset(\"Skywork/Skywork-OR1-RL-Data\", split=\"math\")\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 105055/105055 [00:00<00:00, 592913.56 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 106/106 [00:00<00:00, 330.16ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:08<00:00,  8.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/SDSB/or1_dataset/commit/34ba67440e35c075cd04f2ee1b6e42de38546003', commit_message='Upload dataset', commit_description='', oid='34ba67440e35c075cd04f2ee1b6e42de38546003', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/SDSB/or1_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='SDSB/or1_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add original_question column\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "\n",
    "dataset_df['original_question'] = dataset_df['prompt'].apply(\n",
    "    lambda x: x[0]['content'].strip()\n",
    ")\n",
    "\n",
    "dataset_df['prompt'] = dataset_df['original_question'].apply(\n",
    "    lambda x: [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": x + \" Please output the final answer within \\\\boxed{}.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.Dataset.from_pandas(dataset_df)\n",
    "dataset.save_to_disk(\"or1_dataset\")\n",
    "dataset.push_to_hub(\"SDSB/or1_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_source': 'train-math-numinamath1.5_olympiads',\n",
       " 'prompt': [{'content': '33. How many six-digit numbers are there in which all digits are odd? Please output the final answer within \\\\boxed{}.',\n",
       "   'role': 'user'}],\n",
       " 'ability': 'math',\n",
       " 'reward_model': {'ground_truth': '[\"15625\"]', 'style': 'rule'},\n",
       " 'extra_info': {'index': 7,\n",
       "  'model_difficulty': {'DeepSeek-R1-Distill-Qwen-1.5B': 2,\n",
       "   'DeepSeek-R1-Distill-Qwen-32B': 2,\n",
       "   'DeepSeek-R1-Distill-Qwen-7B': 1}},\n",
       " 'original_question': '33. How many six-digit numbers are there in which all digits are odd?'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 105055/105055 [00:00<00:00, 460320.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_or1 = datasets.load_dataset(\"SDSB/or1_dataset\")\n",
    "dataset_dapo = datasets.load_dataset(\"SDSB/deduplicated_dapo_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['data_source', 'prompt', 'ability', 'reward_model', 'extra_info', 'index', 'original_question', '__index_level_0__'],\n",
       "        num_rows: 17917\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['data_source', 'prompt', 'ability', 'reward_model', 'extra_info', 'index', 'original_question', '__index_level_0__'],\n",
      "    num_rows: 17917\n",
      "})\n",
      "Dataset({\n",
      "    features: ['data_source', 'prompt', 'ability', 'reward_model', 'extra_info', 'original_question'],\n",
      "    num_rows: 105055\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# print keys\n",
    "print(dataset_dapo['train'])\n",
    "print(dataset_or1['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33. How many six-digit numbers are there in which all digits are odd?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_or1['train'][0]['original_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105055/105055 [18:54<00:00, 92.57it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "new_dataset = []\n",
    "raw_question_set = set()\n",
    "for question in tqdm(dataset_or1['train']['original_question']):\n",
    "    # print(question)\n",
    "    if len([question in question_record for question_record in raw_question_set]) == 0 and len([question_record in question for question_record in raw_question_set]) == 0:\n",
    "        new_dataset.append(question)\n",
    "    \n",
    "    raw_question_set.add(question)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['data_source', 'prompt', 'ability', 'reward_model', 'extra_info', 'original_question'],\n",
       "    num_rows: 105055\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_or1['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The features can't be aligned because the key index of features {'index': Value(dtype='string', id=None)} has unexpected type - Value(dtype='string', id=None) (expected either Value(dtype='int64', id=None) or Value(\"null\").",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset_merged = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_or1\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_dapo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/Reasoning360/lib/python3.12/site-packages/datasets/combine.py:213\u001b[39m, in \u001b[36mconcatenate_datasets\u001b[39m\u001b[34m(dsets, info, split, axis)\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    210\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to interleave a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_type.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (at position 0) with a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother_type.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). Expected a list of Dataset objects or a list of IterableDataset objects.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m         )\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dataset_type \u001b[38;5;129;01mis\u001b[39;00m Dataset:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_concatenate_map_style_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _concatenate_iterable_datasets(dsets, info=info, split=split, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/Reasoning360/lib/python3.12/site-packages/datasets/arrow_dataset.py:6174\u001b[39m, in \u001b[36m_concatenate_map_style_datasets\u001b[39m\u001b[34m(dsets, info, split, axis)\u001b[39m\n\u001b[32m   6172\u001b[39m \u001b[38;5;66;03m# Perform checks (and a potentional cast if axis=0)\u001b[39;00m\n\u001b[32m   6173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m6174\u001b[39m     \u001b[43m_check_if_features_can_be_aligned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdsets\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(dset.num_rows == dsets[\u001b[32m0\u001b[39m].num_rows \u001b[38;5;28;01mfor\u001b[39;00m dset \u001b[38;5;129;01min\u001b[39;00m dsets):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/Reasoning360/lib/python3.12/site-packages/datasets/features/features.py:2323\u001b[39m, in \u001b[36m_check_if_features_can_be_aligned\u001b[39m\u001b[34m(features_list)\u001b[39m\n\u001b[32m   2320\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m features.items():\n\u001b[32m   2321\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name2feature[k], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m   2322\u001b[39m         \u001b[38;5;66;03m# Deep checks for structure.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2323\u001b[39m         \u001b[43m_check_if_features_can_be_aligned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname2feature\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2324\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(v, Value) \u001b[38;5;129;01mand\u001b[39;00m v.dtype == \u001b[33m\"\u001b[39m\u001b[33mnull\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name2feature[k] != v:\n\u001b[32m   2325\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2326\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe features can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33mt be aligned because the key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of features \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has unexpected type - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (expected either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname2feature[k]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or Value(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnull\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2327\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/Reasoning360/lib/python3.12/site-packages/datasets/features/features.py:2325\u001b[39m, in \u001b[36m_check_if_features_can_be_aligned\u001b[39m\u001b[34m(features_list)\u001b[39m\n\u001b[32m   2323\u001b[39m     _check_if_features_can_be_aligned([name2feature[k], v])\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(v, Value) \u001b[38;5;129;01mand\u001b[39;00m v.dtype == \u001b[33m\"\u001b[39m\u001b[33mnull\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name2feature[k] != v:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2326\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe features can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33mt be aligned because the key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of features \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has unexpected type - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (expected either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname2feature[k]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or Value(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnull\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2327\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The features can't be aligned because the key index of features {'index': Value(dtype='string', id=None)} has unexpected type - Value(dtype='string', id=None) (expected either Value(dtype='int64', id=None) or Value(\"null\")."
     ]
    }
   ],
   "source": [
    "dataset_merged = datasets.concatenate_datasets([dataset_or1['train'], dataset_dapo['train']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reasoning360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
